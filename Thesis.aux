\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Declaration of Authorship}{i}{dummy.1}}
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{iii}{dummy.2}}
\@writefile{toc}{\vspace  {1em}}
\citation{srivastava2014dropout}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{vii}{dummy.4}}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{ix}{dummy.6}}
\gdef \LT@i {\LT@entry 
    {1}{38.94902pt}\LT@entry 
    {1}{130.6858pt}}
\@writefile{toc}{\contentsline {chapter}{Abbreviations}{x}{dummy.8}}
\gdef \LT@ii {\LT@entry 
    {1}{81.80634pt}\LT@entry 
    {1}{16.7387pt}\LT@entry 
    {1}{20.5167pt}\LT@entry 
    {1}{166.63719pt}}
\@writefile{toc}{\contentsline {chapter}{Physical Constants}{xi}{dummy.11}}
\gdef \LT@iii {\LT@entry 
    {1}{20.5509pt}\LT@entry 
    {1}{97.53178pt}\LT@entry 
    {1}{56.72841pt}}
\@writefile{toc}{\contentsline {chapter}{Symbols}{xii}{dummy.14}}
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.17}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter1}{{1}{2}{Introduction}{chapter.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Overview}{2}{section.18}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Statistical Pattern Recognization}{3}{section.19}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Artificial Neural Networks}{3}{section.20}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Weather Classification}{3}{section.21}}
\citation{bishop1995neural,roser2008classification,serrano2002computationally,gokalp2007scene}
\citation{szummer1998indoor}
\citation{shotton2009textonboost,vailaya2002automatic}
\citation{boutell2004learning,shotton2009textonboost}
\citation{lutwo}
\citation{he2014spatial,roser2008classification}
\citation{roser2008classification,yan2009weather}
\citation{mcculloch1943logical}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}{chapter.22}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter2}{{2}{5}{Background}{chapter.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Related Work}{5}{section.23}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Single-Layer Networks}{5}{section.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Diagram of a perceptron.\relax }}{6}{figure.caption.25}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:perceptron}{{2.1}{6}{Diagram of a perceptron.\relax }{figure.caption.25}{}}
\newlabel{eq:BasicEq}{{2.1}{6}{Single-Layer Networks}{equation.26}{}}
\newlabel{eq:FullEq}{{2.2}{6}{Single-Layer Networks}{equation.27}{}}
\newlabel{eq:LinearFunc}{{2.3}{6}{Single-Layer Networks}{equation.29}{}}
\newlabel{eq:SigmoidFunc}{{2.4}{6}{Single-Layer Networks}{equation.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Threshold function\relax }}{7}{figure.caption.28}}
\newlabel{fig:1LayerErrorSurface}{{2.2}{7}{Threshold function\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Linear function\relax }}{7}{figure.caption.30}}
\newlabel{fig:1LayerErrorSurface}{{2.3}{7}{Linear function\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Sigmoid function\relax }}{7}{figure.caption.32}}
\newlabel{fig:1LayerErrorSurface}{{2.4}{7}{Sigmoid function\relax }{figure.caption.32}{}}
\newlabel{eq:TanhFunc}{{2.5}{7}{Single-Layer Networks}{equation.33}{}}
\newlabel{eq:UsedEq}{{2.6}{7}{Single-Layer Networks}{equation.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Tanh function\relax }}{8}{figure.caption.34}}
\newlabel{fig:1LayerErrorSurface}{{2.5}{8}{Tanh function\relax }{figure.caption.34}{}}
\newlabel{eq:WithBias}{{2.7}{8}{Single-Layer Networks}{equation.36}{}}
\newlabel{eq:finalEq}{{2.8}{8}{Single-Layer Networks}{equation.37}{}}
\newlabel{eq:1LayerExample}{{2.9}{8}{Single-Layer Networks}{equation.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Error surface for a single layer neural network. Source: Internet\relax }}{9}{figure.caption.39}}
\newlabel{fig:1LayerErrorSurface}{{2.6}{9}{Error surface for a single layer neural network. Source: Internet\relax }{figure.caption.39}{}}
\newlabel{fig:a}{{2.7(a)}{9}{Subfigure 2 2.7(a)}{subfigure.41}{}}
\newlabel{sub@fig:a}{{(a)}{9}{Subfigure 2 2.7(a)\relax }{subfigure.41}{}}
\newlabel{fig:b}{{2.7(b)}{9}{Subfigure 2 2.7(b)}{subfigure.42}{}}
\newlabel{sub@fig:b}{{(b)}{9}{Subfigure 2 2.7(b)\relax }{subfigure.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Two types of dataset. Left one can be separated by a single layer neural network. Right one cannot be separated by a single neural network.\relax }}{9}{figure.caption.40}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Multi-Layer Networks}{9}{section.43}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Diagram of a feedford neural networks.\relax }}{10}{figure.caption.44}}
\newlabel{fig:ffnet}{{2.8}{10}{Diagram of a feedford neural networks.\relax }{figure.caption.44}{}}
\newlabel{eq:ffEq}{{2.10}{10}{Multi-Layer Networks}{equation.45}{}}
\newlabel{eq:sigmoid}{{2.11}{10}{Multi-Layer Networks}{equation.46}{}}
\newlabel{eq:tanh}{{2.12}{10}{Multi-Layer Networks}{equation.47}{}}
\newlabel{eq:2LayerExample}{{2.13}{11}{Multi-Layer Networks}{equation.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Error surface for a multilayer neural network. Source: Internet\relax }}{11}{figure.caption.49}}
\newlabel{fig:2LayerErrorSurface}{{2.9}{11}{Error surface for a multilayer neural network. Source: Internet\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces A multilayer neural network can separate a complicated dataset. Source: Internet\relax }}{11}{figure.caption.50}}
\newlabel{fig:2LayerErrorSurface}{{2.10}{11}{A multilayer neural network can separate a complicated dataset. Source: Internet\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Stochastic Gradient Descent}{12}{section.51}}
\newlabel{eq:LossMin}{{2.14}{12}{Stochastic Gradient Descent}{equation.52}{}}
\newlabel{eq:SGDUpdate}{{2.15}{12}{Stochastic Gradient Descent}{equation.53}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Backpropagation}{12}{section.54}}
\newlabel{eq:UpdateWeights}{{2.16}{12}{Backpropagation}{equation.55}{}}
\newlabel{eq:DeltaWeights}{{2.17}{13}{Backpropagation}{equation.56}{}}
\newlabel{eq:h2oBP}{{2.18}{13}{Backpropagation}{equation.57}{}}
\newlabel{eq:hiddenBP}{{2.19}{13}{Backpropagation}{equation.58}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Training protocols}{13}{subsection.59}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Overfitting and Regularization}{14}{section.60}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Overfitting example, left one has a decent generalization performance and right one is overfitting.\relax }}{14}{figure.caption.61}}
\newlabel{fig:OverfittingExample}{{2.11}{14}{Overfitting example, left one has a decent generalization performance and right one is overfitting.\relax }{figure.caption.61}{}}
\citation{hinton1987learning}
\citation{srivastava2014dropout}
\citation{srivastava2014dropout}
\citation{srivastava2014dropout}
\newlabel{eq:Regularization}{{2.20}{15}{Overfitting and Regularization}{equation.62}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Weight Decay}{15}{subsection.63}}
\newlabel{eq:WeightDcay}{{2.21}{15}{Weight Decay}{equation.64}{}}
\newlabel{eq:WeightDecayTime}{{2.22}{15}{Weight Decay}{equation.65}{}}
\newlabel{eq:WeightDecaySolution}{{2.23}{15}{Weight Decay}{equation.66}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Dropout}{15}{subsection.67}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Illustration of dropout \citep  {srivastava2014dropout}.\relax }}{16}{figure.caption.68}}
\newlabel{fig:Dropout}{{2.12}{16}{Illustration of dropout \citep {srivastava2014dropout}.\relax }{figure.caption.68}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Softmax classifier}{16}{section.69}}
\newlabel{eq:SoftmaxActivation}{{2.24}{17}{Softmax classifier}{equation.70}{}}
\newlabel{eq:CrossEntropyDiff}{{2.26}{17}{Softmax classifier}{equation.72}{}}
\newlabel{eq:ProbInter}{{2.27}{17}{Softmax classifier}{equation.73}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Practical issues}{18}{subsection.74}}
\newlabel{eq:SoftmaxTricks}{{2.28}{18}{Practical issues}{equation.75}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Error function}{18}{subsection.76}}
\newlabel{eq:LogLossFunc}{{2.29}{18}{Error function}{equation.77}{}}
\newlabel{eq:LogRegLossFunc}{{2.30}{18}{Error function}{equation.78}{}}
\newlabel{eq:PostProbDis}{{2.32}{18}{Error function}{equation.80}{}}
\citation{lecun1998gradient}
\citation{krizhevsky2012imagenet}
\newlabel{eq:PartDer}{{2.33}{19}{Error function}{equation.81}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Convolutional Neural Networks}{19}{section.82}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Left is a fully connect regular neural network. Right is a CNN in 3 dimensions.\relax }}{19}{figure.caption.83}}
\newlabel{fig:perceptron}{{2.13}{19}{Left is a fully connect regular neural network. Right is a CNN in 3 dimensions.\relax }{figure.caption.83}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Layers in CNN}{19}{subsection.84}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Diagram for depth in convolutional layer\relax }}{20}{figure.caption.89}}
\citation{lazebnik2006beyond}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Spatial Pyramid Matching}{21}{section.90}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Diagram of Spatial Pyramid Match.\relax }}{21}{figure.caption.91}}
\newlabel{fig:perceptron}{{2.15}{21}{Diagram of Spatial Pyramid Match.\relax }{figure.caption.91}{}}
\citation{pan2010survey}
\newlabel{eq:HistInterFunc}{{2.34}{22}{Spatial Pyramid Matching}{equation.92}{}}
\newlabel{eq:PyramidChanMatchKernel}{{2.35}{22}{Spatial Pyramid Matching}{equation.93}{}}
\newlabel{eq:PyramidMatchKernel}{{2.37}{22}{Spatial Pyramid Matching}{equation.94}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Transfer Learning}{22}{section.95}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Lef is traditional ML. Right is Transfer Learning.\relax }}{23}{figure.caption.96}}
\newlabel{fig:perceptron}{{2.16}{23}{Lef is traditional ML. Right is Transfer Learning.\relax }{figure.caption.96}{}}
\newlabel{eq:TransLearning}{{2.38}{23}{Transfer Learning}{equation.97}{}}
\citation{russell2008labelme}
\citation{xiao2010sun}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{24}{chapter.100}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter3}{{3}{24}{Methodology}{chapter.100}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset}{24}{section.101}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces 2 Figures from ImageNet\relax }}{24}{figure.caption.102}}
\newlabel{fig:ImageNetExamples}{{3.1}{24}{2 Figures from ImageNet\relax }{figure.caption.102}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces 2 Figures from Weather Dataset\relax }}{25}{figure.caption.103}}
\newlabel{fig:WeatherExamples}{{3.2}{25}{2 Figures from Weather Dataset\relax }{figure.caption.103}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Data Argument}{25}{section.104}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Spatial Pyramid Pooling}{25}{section.112}}
\citation{krizhevsky2012imagenet}
\citation{nair2010rectified}
\newlabel{fig:orig}{{3.3(a)}{26}{Subfigure 3 3.3(a)}{subfigure.106}{}}
\newlabel{sub@fig:orig}{{(a)}{26}{Subfigure 3 3.3(a)\relax }{subfigure.106}{}}
\newlabel{fig:leftup}{{3.3(b)}{26}{Subfigure 3 3.3(b)}{subfigure.107}{}}
\newlabel{sub@fig:leftup}{{(b)}{26}{Subfigure 3 3.3(b)\relax }{subfigure.107}{}}
\newlabel{fig:leftdown}{{3.3(c)}{26}{Subfigure 3 3.3(c)}{subfigure.108}{}}
\newlabel{sub@fig:leftdown}{{(c)}{26}{Subfigure 3 3.3(c)\relax }{subfigure.108}{}}
\newlabel{fig:rightup}{{3.3(d)}{26}{Subfigure 3 3.3(d)}{subfigure.109}{}}
\newlabel{sub@fig:rightup}{{(d)}{26}{Subfigure 3 3.3(d)\relax }{subfigure.109}{}}
\newlabel{fig:rightdown}{{3.3(e)}{26}{Subfigure 3 3.3(e)}{subfigure.110}{}}
\newlabel{sub@fig:rightdown}{{(e)}{26}{Subfigure 3 3.3(e)\relax }{subfigure.110}{}}
\newlabel{fig:cropcen}{{3.3(f)}{26}{Subfigure 3 3.3(f)}{subfigure.111}{}}
\newlabel{sub@fig:cropcen}{{(f)}{26}{Subfigure 3 3.3(f)\relax }{subfigure.111}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A set of cropped patches from original image\relax }}{26}{figure.caption.105}}
\newlabel{fig:dataargument}{{3.3}{26}{A set of cropped patches from original image\relax }{figure.caption.105}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {original image}}}{26}{figure.caption.105}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {cropped from left up}}}{26}{figure.caption.105}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {cropped from left down}}}{26}{figure.caption.105}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {cropped from right up}}}{26}{figure.caption.105}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {cropped from right down}}}{26}{figure.caption.105}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {cropped from center}}}{26}{figure.caption.105}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Convolutional Neural Networks Architecture}{26}{section.114}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Diagram of Spatial Pyramid Pooling layer\relax }}{27}{figure.caption.113}}
\newlabel{fig:sppnet}{{3.4}{27}{Diagram of Spatial Pyramid Pooling layer\relax }{figure.caption.113}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Architecture of AlexNet\relax }}{27}{figure.caption.115}}
\newlabel{fig:ImageNetArch}{{3.5}{27}{Architecture of AlexNet\relax }{figure.caption.115}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Parameters of model\relax }}{28}{table.caption.116}}
\newlabel{fig:NetPara}{{3.1}{28}{Parameters of model\relax }{table.caption.116}{}}
\citation{jia2014caffe}
\citation{jia2014caffe}
\citation{ZeilerF13}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiment}{29}{chapter.117}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter4}{{4}{29}{Experiment}{chapter.117}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Training Neural Network}{29}{section.118}}
\newlabel{eq:ReLU}{{4.1}{29}{Training Neural Network}{equation.119}{}}
\newlabel{eq:ffEq}{{4.2}{30}{Training Neural Network}{equation.120}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Fine-tuning Model}{30}{section.121}}
\citation{krizhevsky2012imagenet}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Companion Experimental}{31}{section.122}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Experimental Result}{31}{section.123}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces CNN means with original trained model, SPP means model deployed with spatial pyramid pooling layer\relax }}{31}{table.caption.124}}
\newlabel{ExpRes}{{4.1}{31}{CNN means with original trained model, SPP means model deployed with spatial pyramid pooling layer\relax }{table.caption.124}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Finetune Process\relax }}{32}{figure.caption.125}}
\newlabel{fig:finetuneprocess}{{4.1}{32}{Finetune Process\relax }{figure.caption.125}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Finetune Process\relax }}{32}{figure.caption.126}}
\newlabel{fig:FTvsSC}{{4.2}{32}{Finetune Process\relax }{figure.caption.126}{}}
\citation{razavian2014cnn}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces ROC Curve\relax }}{33}{figure.caption.127}}
\newlabel{fig:WeatherClassificationROC}{{4.3}{33}{ROC Curve\relax }{figure.caption.127}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Architecture Analysis}{33}{section.128}}
\newlabel{fig:cloudy}{{4.4(a)}{34}{Subfigure 4 4.4(a)}{subfigure.130}{}}
\newlabel{sub@fig:cloudy}{{(a)}{34}{Subfigure 4 4.4(a)\relax }{subfigure.130}{}}
\newlabel{fig:cloudy_conv1}{{4.4(b)}{34}{Subfigure 4 4.4(b)}{subfigure.131}{}}
\newlabel{sub@fig:cloudy_conv1}{{(b)}{34}{Subfigure 4 4.4(b)\relax }{subfigure.131}{}}
\newlabel{fig:cloudy_conv2}{{4.4(c)}{34}{Subfigure 4 4.4(c)}{subfigure.132}{}}
\newlabel{sub@fig:cloudy_conv2}{{(c)}{34}{Subfigure 4 4.4(c)\relax }{subfigure.132}{}}
\newlabel{fig:cloudy_conv3}{{4.4(d)}{34}{Subfigure 4 4.4(d)}{subfigure.133}{}}
\newlabel{sub@fig:cloudy_conv3}{{(d)}{34}{Subfigure 4 4.4(d)\relax }{subfigure.133}{}}
\newlabel{fig:cloudy_conv4}{{4.4(e)}{34}{Subfigure 4 4.4(e)}{subfigure.134}{}}
\newlabel{sub@fig:cloudy_conv4}{{(e)}{34}{Subfigure 4 4.4(e)\relax }{subfigure.134}{}}
\newlabel{fig:cloudy_conv5}{{4.4(f)}{34}{Subfigure 4 4.4(f)}{subfigure.135}{}}
\newlabel{sub@fig:cloudy_conv5}{{(f)}{34}{Subfigure 4 4.4(f)\relax }{subfigure.135}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces A cloudy image and outputs of convolutional layers\relax }}{34}{figure.caption.129}}
\newlabel{fig:cloudy_finetuneprocess}{{4.4}{34}{A cloudy image and outputs of convolutional layers\relax }{figure.caption.129}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {raw image}}}{34}{figure.caption.129}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {conv1 output}}}{34}{figure.caption.129}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {conv2 output}}}{34}{figure.caption.129}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {conv3 output}}}{34}{figure.caption.129}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {conv4 output}}}{34}{figure.caption.129}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {conv5 output}}}{34}{figure.caption.129}}
\newlabel{fig:sunny}{{4.5(a)}{35}{Subfigure 4 4.5(a)}{subfigure.137}{}}
\newlabel{sub@fig:sunny}{{(a)}{35}{Subfigure 4 4.5(a)\relax }{subfigure.137}{}}
\newlabel{fig:sunny_conv1}{{4.5(b)}{35}{Subfigure 4 4.5(b)}{subfigure.138}{}}
\newlabel{sub@fig:sunny_conv1}{{(b)}{35}{Subfigure 4 4.5(b)\relax }{subfigure.138}{}}
\newlabel{fig:sunny_conv2}{{4.5(c)}{35}{Subfigure 4 4.5(c)}{subfigure.139}{}}
\newlabel{sub@fig:sunny_conv2}{{(c)}{35}{Subfigure 4 4.5(c)\relax }{subfigure.139}{}}
\newlabel{fig:sunny_conv3}{{4.5(d)}{35}{Subfigure 4 4.5(d)}{subfigure.140}{}}
\newlabel{sub@fig:sunny_conv3}{{(d)}{35}{Subfigure 4 4.5(d)\relax }{subfigure.140}{}}
\newlabel{fig:sunny_conv4}{{4.5(e)}{35}{Subfigure 4 4.5(e)}{subfigure.141}{}}
\newlabel{sub@fig:sunny_conv4}{{(e)}{35}{Subfigure 4 4.5(e)\relax }{subfigure.141}{}}
\newlabel{fig:sunny_conv5}{{4.5(f)}{35}{Subfigure 4 4.5(f)}{subfigure.142}{}}
\newlabel{sub@fig:sunny_conv5}{{(f)}{35}{Subfigure 4 4.5(f)\relax }{subfigure.142}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces A sunny image and outputs of convolutional layers\relax }}{35}{figure.caption.136}}
\newlabel{fig:sunny_finetuneprocess}{{4.5}{35}{A sunny image and outputs of convolutional layers\relax }{figure.caption.136}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {raw image}}}{35}{figure.caption.136}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {conv1 output}}}{35}{figure.caption.136}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {conv2 output}}}{35}{figure.caption.136}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {conv3 output}}}{35}{figure.caption.136}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {conv4 output}}}{35}{figure.caption.136}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {conv5 output}}}{35}{figure.caption.136}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Transfer Learning}{35}{section.143}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Error Results}{35}{section.146}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Visiualization of feature maps outputs between original CNN model and CNN-SPP model. The upper images are from original model and the lower images are from fine tuned model\relax }}{36}{figure.caption.144}}
\newlabel{fig:diff_featuremap}{{4.6}{36}{Visiualization of feature maps outputs between original CNN model and CNN-SPP model. The upper images are from original model and the lower images are from fine tuned model\relax }{figure.caption.144}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Histogram distribution of vectors from FC7. Left one is from CNN model and right one is from finetuned model\relax }}{36}{figure.caption.145}}
\newlabel{fig:fc7_hist_output}{{4.7}{36}{Histogram distribution of vectors from FC7. Left one is from CNN model and right one is from finetuned model\relax }{figure.caption.145}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Conclusion and Future Work}{36}{section.154}}
\newlabel{fig:sunny}{{4.8(a)}{37}{Subfigure 4 4.8(a)}{subfigure.148}{}}
\newlabel{sub@fig:sunny}{{(a)}{37}{Subfigure 4 4.8(a)\relax }{subfigure.148}{}}
\newlabel{fig:sunny_conv1}{{4.8(b)}{37}{Subfigure 4 4.8(b)}{subfigure.149}{}}
\newlabel{sub@fig:sunny_conv1}{{(b)}{37}{Subfigure 4 4.8(b)\relax }{subfigure.149}{}}
\newlabel{fig:sunny_conv2}{{4.8(c)}{37}{Subfigure 4 4.8(c)}{subfigure.150}{}}
\newlabel{sub@fig:sunny_conv2}{{(c)}{37}{Subfigure 4 4.8(c)\relax }{subfigure.150}{}}
\newlabel{fig:sunny_conv3}{{4.8(d)}{37}{Subfigure 4 4.8(d)}{subfigure.151}{}}
\newlabel{sub@fig:sunny_conv3}{{(d)}{37}{Subfigure 4 4.8(d)\relax }{subfigure.151}{}}
\newlabel{fig:sunny_conv4}{{4.8(e)}{37}{Subfigure 4 4.8(e)}{subfigure.152}{}}
\newlabel{sub@fig:sunny_conv4}{{(e)}{37}{Subfigure 4 4.8(e)\relax }{subfigure.152}{}}
\newlabel{fig:sunny_conv5}{{4.8(f)}{37}{Subfigure 4 4.8(f)}{subfigure.153}{}}
\newlabel{sub@fig:sunny_conv5}{{(f)}{37}{Subfigure 4 4.8(f)\relax }{subfigure.153}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Misclassified images\relax }}{37}{figure.caption.147}}
\newlabel{fig:Misclassification}{{4.8}{37}{Misclassified images\relax }{figure.caption.147}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {sunny}}}{37}{figure.caption.147}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {sunny}}}{37}{figure.caption.147}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {sunny}}}{37}{figure.caption.147}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {cloudy}}}{37}{figure.caption.147}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {cloudy}}}{37}{figure.caption.147}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {cloudy}}}{37}{figure.caption.147}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Introduction}{38}{chapter.155}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter5}{{5}{38}{Introduction}{chapter.155}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Overview}{38}{section.156}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Example Image\relax }}{38}{figure.caption.157}}
\newlabel{fig:MultilableImage}{{5.1}{38}{Example Image\relax }{figure.caption.157}{}}
\citation{read2011classifier}
\citation{read2011classifier}
\citation{tsoumakas2006multi}
\citation{tsoumakas2007random}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Multilabel $Y_{1},...,Y_{L} \in 2^L$\relax }}{39}{table.caption.158}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Multi-Label Learning}{39}{section.159}}
\citation{ghamrawi2005collective}
\citation{tsoumakas2007random}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Evaluation Metrics}{41}{section.160}}
\newlabel{eq:UniLabel}{{5.1}{41}{Evaluation Metrics}{equation.161}{}}
\newlabel{eq:IndicatorFunc}{{5.2}{41}{Evaluation Metrics}{equation.162}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Example-based Metrics}{42}{subsection.163}}
\newlabel{eq:HammingLoss}{{5.3}{42}{Example-based Metrics}{equation.164}{}}
\newlabel{eq:SubsetAcu}{{5.4}{42}{Example-based Metrics}{equation.165}{}}
\newlabel{eq:Precision}{{5.5}{42}{Example-based Metrics}{equation.166}{}}
\newlabel{eq:Recall}{{5.6}{42}{Example-based Metrics}{equation.167}{}}
\newlabel{eq:Accuracy}{{5.7}{42}{Example-based Metrics}{equation.168}{}}
\newlabel{eq:Accuracy}{{5.8}{42}{Example-based Metrics}{equation.169}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Label-based Metrics}{42}{subsection.170}}
\newlabel{eq:MacroPrecision}{{5.9}{42}{Label-based Metrics}{equation.171}{}}
\newlabel{eq:MacroRecall}{{5.10}{42}{Label-based Metrics}{equation.172}{}}
\citation{gao2013consistency}
\newlabel{eq:LabelAccuracy}{{5.11}{43}{Label-based Metrics}{equation.173}{}}
\newlabel{eq:MicroPrecision}{{5.12}{43}{Label-based Metrics}{equation.174}{}}
\newlabel{eq:MicroRecall}{{5.13}{43}{Label-based Metrics}{equation.175}{}}
\newlabel{eq:LabelMicroAccuracy}{{5.14}{43}{Label-based Metrics}{equation.176}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Learning Algorithms}{43}{section.177}}
\citation{read2011classifier}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Problem Transformation Methods}{44}{subsection.178}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1.1}Binary Relevance}{44}{subsubsection.179}}
\newlabel{eq:BinaryRelevance}{{5.15}{44}{Binary Relevance}{equation.180}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1.2}Classifier Chains}{44}{subsubsection.181}}
\citation{zhang2007ml}
\newlabel{eq:ClassifierChains}{{5.16}{45}{Classifier Chains}{equation.182}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Algorithm Adaptation Methods}{45}{subsection.183}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2.1}Multi-label k-Nearest Neighbor(ML-kNN)}{45}{subsubsection.184}}
\citation{ghamrawi2005collective}
\newlabel{eq:KNNCounting}{{5.17}{46}{Multi-label k-Nearest Neighbor(ML-kNN)}{equation.185}{}}
\newlabel{eq:CategoryVec}{{5.18}{46}{Multi-label k-Nearest Neighbor(ML-kNN)}{equation.186}{}}
\newlabel{eq:CategoryVecBay}{{5.19}{46}{Multi-label k-Nearest Neighbor(ML-kNN)}{equation.187}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2.2}Collective Multi-label Classifier(CML)}{46}{subsubsection.188}}
\newlabel{eq:CMLExpect}{{5.20}{46}{Collective Multi-label Classifier(CML)}{equation.189}{}}
\newlabel{eq:CMLOptimal}{{5.21}{47}{Collective Multi-label Classifier(CML)}{equation.190}{}}
\newlabel{eq:CMLLabel}{{5.22}{47}{Collective Multi-label Classifier(CML)}{equation.191}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Multi-lable Classification Methodology}{48}{chapter.192}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter6}{{6}{48}{Multi-lable Classification Methodology}{chapter.192}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Artificial Dataset}{48}{section.193}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Colour Wheel Diagram\relax }}{48}{figure.caption.194}}
\newlabel{fig:ColorWheel}{{6.1}{48}{Colour Wheel Diagram\relax }{figure.caption.194}{}}
\citation{barron1993universal}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Manufacturing data}{49}{subsection.195}}
\newlabel{eq:FormulationHue}{{6.1}{49}{Manufacturing data}{equation.196}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Artificial Neural Networks}{49}{section.214}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces A multilabel sample and RGB color histograms. Three labels mean red, green and blue. \relax }}{50}{figure.caption.197}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Label:1 -1 1}}}{50}{figure.caption.197}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Label:1 1 -1}}}{50}{figure.caption.197}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {Label:-1 1 -1}}}{50}{figure.caption.197}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(m)}{\ignorespaces {Label:-1 -1 1}}}{50}{figure.caption.197}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Network Architecture}{50}{subsection.215}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Network Topology For Multi-lable classification\relax }}{51}{figure.caption.216}}
\newlabel{fig:MultiLabelNet}{{6.3}{51}{Network Topology For Multi-lable classification\relax }{figure.caption.216}{}}
\newlabel{eq:MultiLableError}{{6.2}{51}{Network Architecture}{equation.217}{}}
\newlabel{eq:MultiLableSamError}{{6.3}{51}{Network Architecture}{equation.218}{}}
\newlabel{eq:MultiLableGlobalError}{{6.4}{52}{Network Architecture}{equation.219}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Error Function}{52}{subsection.220}}
\citation{bermejo2001oriented}
\newlabel{eq:JointProbDensity}{{6.5}{53}{Error Function}{equation.221}{}}
\newlabel{eq:ProbDensityX}{{6.6}{53}{Error Function}{equation.222}{}}
\newlabel{eq:LikelihoodLoss}{{6.7}{53}{Error Function}{equation.223}{}}
\newlabel{eq:LikelihoodErrorFunc}{{6.8}{53}{Error Function}{equation.224}{}}
\newlabel{eq:SimLikelihoodErrorFunc}{{6.9}{53}{Error Function}{equation.225}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Cross Entropy}{53}{subsection.226}}
\newlabel{eq:RelativeEngtropy}{{6.10}{54}{Cross Entropy}{equation.227}{}}
\newlabel{eq:EquationNN}{{6.11}{54}{Cross Entropy}{equation.228}{}}
\newlabel{eq:TwoClassCrossEntropyCostFunc}{{6.12}{54}{Cross Entropy}{equation.229}{}}
\newlabel{eq:DerCrossEntropyCostFunc}{{6.13}{55}{Cross Entropy}{equation.230}{}}
\newlabel{eq:SecondDerCrossEntropyCostFunc}{{6.15}{55}{Cross Entropy}{equation.231}{}}
\newlabel{eq:SimDerCrossEntropyCostFunc}{{6.16}{55}{Cross Entropy}{equation.232}{}}
\newlabel{eq:BiasCrossEntropyCostFunc}{{6.17}{55}{Cross Entropy}{equation.233}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Training and Testing}{55}{subsection.234}}
\newlabel{eq:MultiLabelActivation}{{6.18}{55}{Training and Testing}{equation.235}{}}
\newlabel{eq:MultiLabel}{{6.19}{55}{Training and Testing}{equation.236}{}}
\newlabel{eq:MultiLableErrorDif}{{6.20}{56}{Training and Testing}{equation.237}{}}
\newlabel{eq:MultiLableChainRule}{{6.21}{56}{Training and Testing}{equation.238}{}}
\newlabel{eq:MultiLablePartialC}{{6.22}{56}{Training and Testing}{equation.239}{}}
\newlabel{eq:MultiLableGenErr}{{6.23}{56}{Training and Testing}{equation.240}{}}
\newlabel{eq:MultiLableGenErrS}{{6.24}{56}{Training and Testing}{equation.241}{}}
\newlabel{eq:MultiLablePartialE}{{6.25}{56}{Training and Testing}{equation.242}{}}
\newlabel{eq:MultiLableGenErrEs}{{6.26}{56}{Training and Testing}{equation.243}{}}
\newlabel{eq:MultiLableGenErrEsFin}{{6.27}{56}{Training and Testing}{equation.244}{}}
\citation{elisseeff2001kernel}
\newlabel{eq:MultiLableUpdateWeights}{{6.28}{57}{Training and Testing}{equation.245}{}}
\newlabel{eq:MultiLableUpdateHidWeights}{{6.29}{57}{Training and Testing}{equation.246}{}}
\newlabel{eq:MultiLableUpdateBias}{{6.30}{57}{Training and Testing}{equation.247}{}}
\newlabel{eq:MultiLableThreshFunc}{{6.31}{57}{Training and Testing}{equation.248}{}}
\citation{lippmann1987introduction}
\citation{kolmogorov1963representation}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Experiment}{58}{section.249}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Dataset}{58}{subsection.250}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Details of network}{58}{subsection.251}}
\citation{heaton2008introduction}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Network topology for multilable classification.\relax }}{59}{figure.caption.252}}
\newlabel{fig:MLtopology}{{6.4}{59}{Network topology for multilable classification.\relax }{figure.caption.252}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Results}{60}{subsection.263}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Test results for different number of hidden neurons.\relax }}{61}{table.caption.264}}
\newlabel{tb:tMLtestneurons}{{6.1}{61}{Test results for different number of hidden neurons.\relax }{table.caption.264}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Test results for different number of hidden neurons. Blue circle for Sensitivity. Black plus for Specificity. Cyan star for Harmonic Mean. Red dot for Precission. Green x for F1 Score.\relax }}{61}{figure.caption.265}}
\newlabel{fig:MLtestneurons}{{6.5}{61}{Test results for different number of hidden neurons. Blue circle for Sensitivity. Black plus for Specificity. Cyan star for Harmonic Mean. Red dot for Precission. Green x for F1 Score.\relax }{figure.caption.265}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Conclusion and Future Work}{61}{section.268}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces ROC curve for 200 hidden neurons\relax }}{62}{figure.caption.266}}
\newlabel{fig:MLROCCurve}{{6.6}{62}{ROC curve for 200 hidden neurons\relax }{figure.caption.266}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces ROC curve for 200 hidden neurons\relax }}{62}{figure.caption.267}}
\newlabel{fig:MLROCCurveExt}{{6.7}{62}{ROC curve for 200 hidden neurons\relax }{figure.caption.267}{}}
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix Title Here}{63}{appendix.269}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{AppendixA}{{A}{63}{Appendix Title Here}{appendix.269}{}}
\@writefile{toc}{\vspace  {2em}}
\bibstyle{unsrtnat}
\bibdata{Bibliography}
\bibcite{srivastava2014dropout}{{1}{2014}{{Srivastava et~al.}}{{Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov}}}
\bibcite{bishop1995neural}{{2}{1995}{{Bishop}}{{}}}
\bibcite{roser2008classification}{{3}{2008}{{Roser and Moosmann}}{{}}}
\bibcite{serrano2002computationally}{{4}{2002}{{Serrano et~al.}}{{Serrano, Savakis, and Luo}}}
\bibcite{gokalp2007scene}{{5}{2007}{{Gokalp and Aksoy}}{{}}}
\bibcite{szummer1998indoor}{{6}{1998}{{Szummer and Picard}}{{}}}
\bibcite{shotton2009textonboost}{{7}{2009}{{Shotton et~al.}}{{Shotton, Winn, Rother, and Criminisi}}}
\bibcite{vailaya2002automatic}{{8}{2002}{{Vailaya et~al.}}{{Vailaya, Zhang, Yang, Liu, and Jain}}}
\bibcite{boutell2004learning}{{9}{2004}{{Boutell et~al.}}{{Boutell, Luo, Shen, and Brown}}}
\bibcite{lutwo}{{10}{2014}{{Lu et~al.}}{{Lu, Lin, Jia, and Tang}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{64}{dummy.270}}
\newlabel{Bibliography}{{8}{64}{Appendix Title Here}{dummy.270}{}}
\bibcite{he2014spatial}{{11}{2014}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{yan2009weather}{{12}{2009}{{Yan et~al.}}{{Yan, Luo, and Zheng}}}
\bibcite{mcculloch1943logical}{{13}{1943}{{McCulloch and Pitts}}{{}}}
\bibcite{hinton1987learning}{{14}{1987}{{Hinton}}{{}}}
\bibcite{lecun1998gradient}{{15}{1998}{{LeCun et~al.}}{{LeCun, Bottou, Bengio, and Haffner}}}
\bibcite{krizhevsky2012imagenet}{{16}{2012}{{Krizhevsky et~al.}}{{Krizhevsky, Sutskever, and Hinton}}}
\bibcite{lazebnik2006beyond}{{17}{2006}{{Lazebnik et~al.}}{{Lazebnik, Schmid, and Ponce}}}
\bibcite{pan2010survey}{{18}{2010}{{Pan and Yang}}{{}}}
\bibcite{russell2008labelme}{{19}{2008}{{Russell et~al.}}{{Russell, Torralba, Murphy, and Freeman}}}
\bibcite{xiao2010sun}{{20}{2010}{{Xiao et~al.}}{{Xiao, Hays, Ehinger, Oliva, Torralba, et~al.}}}
\bibcite{nair2010rectified}{{21}{2010}{{Nair and Hinton}}{{}}}
\bibcite{jia2014caffe}{{22}{2014}{{Jia et~al.}}{{Jia, Shelhamer, Donahue, Karayev, Long, Girshick, Guadarrama, and Darrell}}}
\bibcite{ZeilerF13}{{23}{2013}{{Zeiler and Fergus}}{{}}}
\bibcite{razavian2014cnn}{{24}{2014}{{Razavian et~al.}}{{Razavian, Azizpour, Sullivan, and Carlsson}}}
\bibcite{read2011classifier}{{25}{2011}{{Read et~al.}}{{Read, Pfahringer, Holmes, and Frank}}}
\bibcite{tsoumakas2006multi}{{26}{2006}{{Tsoumakas and Katakis}}{{}}}
\bibcite{tsoumakas2007random}{{27}{2007}{{Tsoumakas and Vlahavas}}{{}}}
\bibcite{ghamrawi2005collective}{{28}{2005}{{Ghamrawi and McCallum}}{{}}}
\bibcite{gao2013consistency}{{29}{2013}{{Gao and Zhou}}{{}}}
\bibcite{zhang2007ml}{{30}{2007}{{Zhang and Zhou}}{{}}}
\bibcite{barron1993universal}{{31}{1993}{{Barron}}{{}}}
\bibcite{bermejo2001oriented}{{32}{2001}{{Bermejo and Cabestany}}{{}}}
\bibcite{elisseeff2001kernel}{{33}{2001}{{Elisseeff and Weston}}{{}}}
\bibcite{lippmann1987introduction}{{34}{1987}{{Lippmann}}{{}}}
\bibcite{kolmogorov1963representation}{{35}{1963}{{Kolmogorov}}{{}}}
\bibcite{heaton2008introduction}{{36}{2008}{{Heaton}}{{}}}
