\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Declaration of Authorship}{i}{dummy.1}}
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{iii}{dummy.2}}
\@writefile{toc}{\vspace  {1em}}
\citation{NeuronFigure1}
\citation{ErrorFigure1}
\citation{GenerateNN}
\citation{zainal2013oil}
\citation{ErrorFigure1}
\citation{GenerateNN}
\citation{OverfittingFigure}
\citation{srivastava2014dropout}
\citation{CNNDiagram}
\citation{CNNDiagram}
\citation{lazebnik2006beyond}
\citation{TransferlearningDiagram}
\citation{deng2009imagenet}
\citation{lutwo}
\citation{he2014spatial}
\citation{krizhevsky2012imagenet}
\citation{lutwo}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{vii}{dummy.4}}
\citation{ColourWheel}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{ix}{dummy.6}}
\gdef \LT@i {\LT@entry 
    {1}{46.19728pt}\LT@entry 
    {1}{181.16226pt}}
\@writefile{toc}{\contentsline {chapter}{Abbreviations}{x}{dummy.8}}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Weather Classification}{xi}{part.11}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.12}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter1}{{1}{1}{Introduction}{chapter.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Overview}{1}{section.13}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Statistical Pattern Recognisation}{2}{section.14}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Artificial Neural Networks (ANNs)}{2}{section.15}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Weather Classification}{2}{section.16}}
\citation{bishop1995neural,roser2008classification,serrano2002computationally,gokalp2007scene}
\citation{szummer1998indoor}
\citation{shotton2009textonboost,vailaya2002automatic}
\citation{boutell2004learning,shotton2009textonboost}
\citation{lutwo}
\citation{he2014spatial,roser2008classification}
\citation{roser2008classification,yan2009weather}
\citation{mcculloch1943logical}
\citation{NeuronFigure1}
\citation{NeuronFigure1}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{4}{chapter.17}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter2}{{2}{4}{Background}{chapter.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Related Work}{4}{section.18}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Single-Layer ANNs}{5}{section.19}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Diagram of a perceptron \citep  {NeuronFigure1}.\relax }}{5}{figure.caption.20}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:perceptron}{{2.1}{5}{Diagram of a perceptron \citep {NeuronFigure1}.\relax }{figure.caption.20}{}}
\newlabel{eq:BasicEq}{{2.1}{5}{Single-Layer ANNs}{equation.21}{}}
\newlabel{eq:FullEq}{{2.2}{5}{Single-Layer ANNs}{equation.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Threshold function\relax }}{6}{figure.caption.23}}
\newlabel{fig:ThresholdFunc}{{2.2}{6}{Threshold function\relax }{figure.caption.23}{}}
\newlabel{eq:LinearFunc}{{2.3}{6}{Single-Layer ANNs}{equation.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Linear function\relax }}{6}{figure.caption.25}}
\newlabel{fig:LinearFunc}{{2.3}{6}{Linear function\relax }{figure.caption.25}{}}
\newlabel{eq:SigmoidFunc}{{2.4}{6}{Single-Layer ANNs}{equation.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Sigmoid function\relax }}{6}{figure.caption.27}}
\newlabel{fig:SigmoidFunc}{{2.4}{6}{Sigmoid function\relax }{figure.caption.27}{}}
\newlabel{eq:TanhFunc}{{2.5}{6}{Single-Layer ANNs}{equation.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Tanh function\relax }}{6}{figure.caption.29}}
\newlabel{fig:TanhFunc}{{2.5}{6}{Tanh function\relax }{figure.caption.29}{}}
\citation{ErrorFigure1}
\citation{ErrorFigure1}
\citation{GenerateNN}
\citation{GenerateNN}
\newlabel{eq:UsedEq}{{2.6}{7}{Single-Layer ANNs}{equation.30}{}}
\newlabel{eq:WithBias}{{2.7}{7}{Single-Layer ANNs}{equation.31}{}}
\newlabel{eq:finalEq}{{2.8}{7}{Single-Layer ANNs}{equation.32}{}}
\newlabel{eq:1LayerExample}{{2.9}{7}{Single-Layer ANNs}{equation.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The error surface for a single layer neural network \citep  {ErrorFigure1}.\relax }}{8}{figure.caption.34}}
\newlabel{fig:1LayerErrorSurface}{{2.6}{8}{The error surface for a single layer neural network \citep {ErrorFigure1}.\relax }{figure.caption.34}{}}
\newlabel{fig:a}{{2.7(a)}{8}{Subfigure 2 2.7(a)}{subfigure.36}{}}
\newlabel{sub@fig:a}{{(a)}{8}{Subfigure 2 2.7(a)\relax }{subfigure.36}{}}
\newlabel{fig:b}{{2.7(b)}{8}{Subfigure 2 2.7(b)}{subfigure.37}{}}
\newlabel{sub@fig:b}{{(b)}{8}{Subfigure 2 2.7(b)\relax }{subfigure.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Two types of dataset. The left one can be separated by a single layer neural network. The right one cannot be separated by a single neural network. Generated from \citep  {GenerateNN}.\relax }}{8}{figure.caption.35}}
\newlabel{fig:1Layer2datasets}{{2.7}{8}{Two types of dataset. The left one can be separated by a single layer neural network. The right one cannot be separated by a single neural network. Generated from \citep {GenerateNN}.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Multi-Layer Networks}{8}{section.38}}
\citation{zainal2013oil}
\citation{zainal2013oil}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Diagram of a feedforward neural network \citep  {zainal2013oil}.\relax }}{9}{figure.caption.39}}
\newlabel{fig:ffnet}{{2.8}{9}{Diagram of a feedforward neural network \citep {zainal2013oil}.\relax }{figure.caption.39}{}}
\newlabel{eq:ffEq}{{2.10}{9}{Multi-Layer Networks}{equation.40}{}}
\newlabel{eq:sigmoid}{{2.11}{9}{Multi-Layer Networks}{equation.41}{}}
\citation{ErrorFigure1}
\citation{ErrorFigure1}
\citation{GenerateNN}
\citation{GenerateNN}
\newlabel{eq:tanh}{{2.12}{10}{Multi-Layer Networks}{equation.42}{}}
\newlabel{eq:2LayerExample}{{2.13}{10}{Multi-Layer Networks}{equation.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces The error surface for a multi-layer neural network \citep  {ErrorFigure1}.\relax }}{10}{figure.caption.44}}
\newlabel{fig:2LayerErrorSurface}{{2.9}{10}{The error surface for a multi-layer neural network \citep {ErrorFigure1}.\relax }{figure.caption.44}{}}
\citation{robbins1985convergence}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces A multi-layer neural network can separate a complicated dataset. Generated from \citep  {GenerateNN}.\relax }}{11}{figure.caption.45}}
\newlabel{fig:MultiLayerErrorSurface}{{2.10}{11}{A multi-layer neural network can separate a complicated dataset. Generated from \citep {GenerateNN}.\relax }{figure.caption.45}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Stochastic Gradient Descent (SGD)}{11}{section.46}}
\newlabel{eq:LossMin}{{2.14}{11}{Stochastic Gradient Descent (SGD)}{equation.47}{}}
\newlabel{eq:SGDUpdate}{{2.15}{11}{Stochastic Gradient Descent (SGD)}{equation.48}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Backpropagation}{11}{section.49}}
\newlabel{eq:UpdateWeights}{{2.16}{12}{Backpropagation}{equation.50}{}}
\newlabel{eq:DeltaWeights}{{2.17}{12}{Backpropagation}{equation.51}{}}
\newlabel{eq:h2oBP}{{2.18}{12}{Backpropagation}{equation.52}{}}
\newlabel{eq:hiddenBP}{{2.19}{12}{Backpropagation}{equation.53}{}}
\citation{OverfittingFigure}
\citation{OverfittingFigure}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Training protocols}{13}{subsection.54}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Overfitting and Regularization}{13}{section.55}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Overfitting example, the left one has a decent generalisation performance and the right one is overfitting \citep  {OverfittingFigure}.\relax }}{14}{figure.caption.56}}
\newlabel{fig:OverfittingExample}{{2.11}{14}{Overfitting example, the left one has a decent generalisation performance and the right one is overfitting \citep {OverfittingFigure}.\relax }{figure.caption.56}{}}
\newlabel{eq:Regularization}{{2.20}{14}{Overfitting and Regularization}{equation.57}{}}
\citation{hinton1987learning}
\citation{srivastava2014dropout}
\citation{srivastava2014dropout}
\citation{srivastava2014dropout}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Weight Decay}{15}{subsection.58}}
\newlabel{eq:WeightDcay}{{2.21}{15}{Weight Decay}{equation.59}{}}
\newlabel{eq:WeightDecayTime}{{2.22}{15}{Weight Decay}{equation.60}{}}
\newlabel{eq:WeightDecaySolution}{{2.23}{15}{Weight Decay}{equation.61}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Dropout}{15}{subsection.62}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Illustration of dropout \citep  {srivastava2014dropout}.\relax }}{16}{figure.caption.63}}
\newlabel{fig:Dropout}{{2.12}{16}{Illustration of dropout \citep {srivastava2014dropout}.\relax }{figure.caption.63}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Softmax Classifier}{16}{section.64}}
\newlabel{eq:SoftmaxActivation}{{2.24}{16}{Softmax Classifier}{equation.65}{}}
\newlabel{eq:CrossEntropyDiff}{{2.26}{17}{Softmax Classifier}{equation.67}{}}
\newlabel{eq:ProbInter}{{2.27}{17}{Softmax Classifier}{equation.68}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Practical issues}{18}{subsection.69}}
\newlabel{eq:SoftmaxTricks}{{2.28}{18}{Practical issues}{equation.70}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Error function}{18}{subsection.71}}
\newlabel{eq:LogLossFunc}{{2.29}{18}{Error function}{equation.72}{}}
\newlabel{eq:LogRegLossFunc}{{2.30}{18}{Error function}{equation.73}{}}
\newlabel{eq:PostProbDis}{{2.32}{18}{Error function}{equation.75}{}}
\citation{lecun1998gradient}
\citation{krizhevsky2012imagenet}
\citation{CNNDiagram}
\citation{CNNDiagram}
\newlabel{eq:PartDer}{{2.33}{19}{Error function}{equation.76}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Convolutional Neural Networks (CNN)}{19}{section.77}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces The left is a fully connect regular neural network. The right is a CNN in 3 dimensions \citep  {CNNDiagram}.\relax }}{19}{figure.caption.78}}
\newlabel{fig:compareCNNandFC}{{2.13}{19}{The left is a fully connect regular neural network. The right is a CNN in 3 dimensions \citep {CNNDiagram}.\relax }{figure.caption.78}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Layers in CNN}{19}{subsection.79}}
\citation{CNNDiagram}
\citation{CNNDiagram}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Diagram for depth in a convolutional layer \citep  {CNNDiagram}.\relax }}{20}{figure.caption.84}}
\citation{lazebnik2006beyond}
\citation{lazebnik2006beyond}
\citation{lazebnik2006beyond}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Spatial Pyramid Matching (SPM)}{21}{section.85}}
\citation{pan2010survey}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Diagram of the Spatial Pyramid Matching \citep  {lazebnik2006beyond}.\relax }}{22}{figure.caption.86}}
\newlabel{fig:SpatialPyramidMatching}{{2.15}{22}{Diagram of the Spatial Pyramid Matching \citep {lazebnik2006beyond}.\relax }{figure.caption.86}{}}
\newlabel{eq:HistInterFunc}{{2.34}{22}{Spatial Pyramid Matching (SPM)}{equation.87}{}}
\newlabel{eq:PyramidChanMatchKernel}{{2.35}{22}{Spatial Pyramid Matching (SPM)}{equation.88}{}}
\newlabel{eq:PyramidMatchKernel}{{2.37}{22}{Spatial Pyramid Matching (SPM)}{equation.89}{}}
\citation{TransferlearningDiagram}
\citation{TransferlearningDiagram}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Transfer Learning}{23}{section.90}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces The left is traditional machine learning method. The right is transfer learning \citep  {TransferlearningDiagram}.\relax }}{23}{figure.caption.91}}
\newlabel{fig:TransferLearning}{{2.16}{23}{The left is traditional machine learning method. The right is transfer learning \citep {TransferlearningDiagram}.\relax }{figure.caption.91}{}}
\newlabel{eq:TransLearning}{{2.38}{23}{Transfer Learning}{equation.92}{}}
\citation{deng2009imagenet}
\citation{deng2009imagenet}
\citation{deng2009imagenet}
\citation{lutwo}
\citation{russell2008labelme}
\citation{xiao2010sun}
\citation{lutwo}
\citation{lutwo}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{25}{chapter.95}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter3}{{3}{25}{Methodology}{chapter.95}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset}{25}{section.96}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces 2 Figures from the ImageNet \citep  {deng2009imagenet}.\relax }}{25}{figure.caption.97}}
\newlabel{fig:ImageNetExamples}{{3.1}{25}{2 Figures from the ImageNet \citep {deng2009imagenet}.\relax }{figure.caption.97}{}}
\citation{krizhevsky2012imagenet}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces 2 Figures from the Weather Dataset \citep  {lutwo}.\relax }}{26}{figure.caption.98}}
\newlabel{fig:WeatherExamples}{{3.2}{26}{2 Figures from the Weather Dataset \citep {lutwo}.\relax }{figure.caption.98}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Data Argumentation}{26}{section.99}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Spatial Pyramid Pooling (SPP)}{26}{section.107}}
\citation{he2014spatial}
\citation{he2014spatial}
\citation{krizhevsky2012imagenet}
\citation{krizhevsky2012imagenet}
\citation{krizhevsky2012imagenet}
\citation{nair2010rectified}
\newlabel{fig:orig}{{3.3(a)}{27}{Subfigure 3 3.3(a)}{subfigure.101}{}}
\newlabel{sub@fig:orig}{{(a)}{27}{Subfigure 3 3.3(a)\relax }{subfigure.101}{}}
\newlabel{fig:leftup}{{3.3(b)}{27}{Subfigure 3 3.3(b)}{subfigure.102}{}}
\newlabel{sub@fig:leftup}{{(b)}{27}{Subfigure 3 3.3(b)\relax }{subfigure.102}{}}
\newlabel{fig:leftdown}{{3.3(c)}{27}{Subfigure 3 3.3(c)}{subfigure.103}{}}
\newlabel{sub@fig:leftdown}{{(c)}{27}{Subfigure 3 3.3(c)\relax }{subfigure.103}{}}
\newlabel{fig:rightup}{{3.3(d)}{27}{Subfigure 3 3.3(d)}{subfigure.104}{}}
\newlabel{sub@fig:rightup}{{(d)}{27}{Subfigure 3 3.3(d)\relax }{subfigure.104}{}}
\newlabel{fig:rightdown}{{3.3(e)}{27}{Subfigure 3 3.3(e)}{subfigure.105}{}}
\newlabel{sub@fig:rightdown}{{(e)}{27}{Subfigure 3 3.3(e)\relax }{subfigure.105}{}}
\newlabel{fig:cropcen}{{3.3(f)}{27}{Subfigure 3 3.3(f)}{subfigure.106}{}}
\newlabel{sub@fig:cropcen}{{(f)}{27}{Subfigure 3 3.3(f)\relax }{subfigure.106}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A set of cropped patches from original image\relax }}{27}{figure.caption.100}}
\newlabel{fig:dataargument}{{3.3}{27}{A set of cropped patches from original image\relax }{figure.caption.100}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {original image}}}{27}{figure.caption.100}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {cropped from left up}}}{27}{figure.caption.100}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {cropped from left down}}}{27}{figure.caption.100}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {cropped from right up}}}{27}{figure.caption.100}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {cropped from right down}}}{27}{figure.caption.100}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {cropped from center}}}{27}{figure.caption.100}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Convolutional Neural Networks Architecture}{27}{section.109}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Diagram of the SPP layer \citep  {he2014spatial}\relax }}{28}{figure.caption.108}}
\newlabel{fig:sppnet}{{3.4}{28}{Diagram of the SPP layer \citep {he2014spatial}\relax }{figure.caption.108}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Architecture of the AlexNet \citep  {krizhevsky2012imagenet}\relax }}{28}{figure.caption.110}}
\newlabel{fig:ImageNetArch}{{3.5}{28}{Architecture of the AlexNet \citep {krizhevsky2012imagenet}\relax }{figure.caption.110}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Architecture of the model\relax }}{29}{table.caption.111}}
\newlabel{fig:NetPara}{{3.1}{29}{Architecture of the model\relax }{table.caption.111}{}}
\citation{jia2014caffe}
\citation{ZeilerF13}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiment}{30}{chapter.112}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter4}{{4}{30}{Experiment}{chapter.112}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Training Neural Networks}{30}{section.113}}
\newlabel{eq:ReLU}{{4.1}{30}{Training Neural Networks}{equation.114}{}}
\newlabel{eq:WeightDecay}{{4.2}{31}{Training Neural Networks}{equation.115}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Fine-tuning Model}{31}{section.116}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Companion Experiments}{32}{section.117}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Experimental Results}{32}{section.118}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces The first test is extracting features from the pre-trained CNN model and training a SVM classifer. The second test is similar with the first except for extracting features from the CNN model with a SPP layer. The third test is fine-tuning the model with AlexNet architecture. The fourth test is fine-tuning the CNN model with a SPP layer\relax }}{32}{table.caption.119}}
\newlabel{ExpRes}{{4.1}{32}{The first test is extracting features from the pre-trained CNN model and training a SVM classifer. The second test is similar with the first except for extracting features from the CNN model with a SPP layer. The third test is fine-tuning the model with AlexNet architecture. The fourth test is fine-tuning the CNN model with a SPP layer\relax }{table.caption.119}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Learning Process\relax }}{33}{figure.caption.120}}
\newlabel{fig:finetuneprocess}{{4.1}{33}{Learning Process\relax }{figure.caption.120}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Training Loss\relax }}{33}{figure.caption.121}}
\newlabel{fig:FTvsSC}{{4.2}{33}{Training Loss\relax }{figure.caption.121}{}}
\citation{razavian2014cnn}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces ROC Curve\relax }}{34}{figure.caption.122}}
\newlabel{fig:WeatherClassificationROC}{{4.3}{34}{ROC Curve\relax }{figure.caption.122}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Architecture Analysis}{34}{section.123}}
\newlabel{fig:cloudy}{{4.4(a)}{35}{Subfigure 4 4.4(a)}{subfigure.125}{}}
\newlabel{sub@fig:cloudy}{{(a)}{35}{Subfigure 4 4.4(a)\relax }{subfigure.125}{}}
\newlabel{fig:cloudy_conv1}{{4.4(b)}{35}{Subfigure 4 4.4(b)}{subfigure.126}{}}
\newlabel{sub@fig:cloudy_conv1}{{(b)}{35}{Subfigure 4 4.4(b)\relax }{subfigure.126}{}}
\newlabel{fig:cloudy_conv2}{{4.4(c)}{35}{Subfigure 4 4.4(c)}{subfigure.127}{}}
\newlabel{sub@fig:cloudy_conv2}{{(c)}{35}{Subfigure 4 4.4(c)\relax }{subfigure.127}{}}
\newlabel{fig:cloudy_conv3}{{4.4(d)}{35}{Subfigure 4 4.4(d)}{subfigure.128}{}}
\newlabel{sub@fig:cloudy_conv3}{{(d)}{35}{Subfigure 4 4.4(d)\relax }{subfigure.128}{}}
\newlabel{fig:cloudy_conv4}{{4.4(e)}{35}{Subfigure 4 4.4(e)}{subfigure.129}{}}
\newlabel{sub@fig:cloudy_conv4}{{(e)}{35}{Subfigure 4 4.4(e)\relax }{subfigure.129}{}}
\newlabel{fig:cloudy_conv5}{{4.4(f)}{35}{Subfigure 4 4.4(f)}{subfigure.130}{}}
\newlabel{sub@fig:cloudy_conv5}{{(f)}{35}{Subfigure 4 4.4(f)\relax }{subfigure.130}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces A cloudy image and the feature maps from convolutional layers\relax }}{35}{figure.caption.124}}
\newlabel{fig:cloudy_finetuneprocess}{{4.4}{35}{A cloudy image and the feature maps from convolutional layers\relax }{figure.caption.124}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {raw image}}}{35}{figure.caption.124}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {conv1 output}}}{35}{figure.caption.124}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {conv2 output}}}{35}{figure.caption.124}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {conv3 output}}}{35}{figure.caption.124}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {conv4 output}}}{35}{figure.caption.124}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {conv5 output}}}{35}{figure.caption.124}}
\citation{lutwo}
\citation{lutwo}
\newlabel{fig:sunny_ft}{{4.5(a)}{36}{Subfigure 4 4.5(a)}{subfigure.132}{}}
\newlabel{sub@fig:sunny_ft}{{(a)}{36}{Subfigure 4 4.5(a)\relax }{subfigure.132}{}}
\newlabel{fig:sunny_ft_conv1}{{4.5(b)}{36}{Subfigure 4 4.5(b)}{subfigure.133}{}}
\newlabel{sub@fig:sunny_ft_conv1}{{(b)}{36}{Subfigure 4 4.5(b)\relax }{subfigure.133}{}}
\newlabel{fig:sunny_ft_conv2}{{4.5(c)}{36}{Subfigure 4 4.5(c)}{subfigure.134}{}}
\newlabel{sub@fig:sunny_ft_conv2}{{(c)}{36}{Subfigure 4 4.5(c)\relax }{subfigure.134}{}}
\newlabel{fig:sunny_ft_conv3}{{4.5(d)}{36}{Subfigure 4 4.5(d)}{subfigure.135}{}}
\newlabel{sub@fig:sunny_ft_conv3}{{(d)}{36}{Subfigure 4 4.5(d)\relax }{subfigure.135}{}}
\newlabel{fig:sunny_ft_conv4}{{4.5(e)}{36}{Subfigure 4 4.5(e)}{subfigure.136}{}}
\newlabel{sub@fig:sunny_ft_conv4}{{(e)}{36}{Subfigure 4 4.5(e)\relax }{subfigure.136}{}}
\newlabel{fig:sunny_ft_conv5}{{4.5(f)}{36}{Subfigure 4 4.5(f)}{subfigure.137}{}}
\newlabel{sub@fig:sunny_ft_conv5}{{(f)}{36}{Subfigure 4 4.5(f)\relax }{subfigure.137}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces A sunny image and the feature maps from convolutional layers\relax }}{36}{figure.caption.131}}
\newlabel{fig:sunny_finetuneprocess}{{4.5}{36}{A sunny image and the feature maps from convolutional layers\relax }{figure.caption.131}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {raw image}}}{36}{figure.caption.131}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {conv1 output}}}{36}{figure.caption.131}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {conv2 output}}}{36}{figure.caption.131}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {conv3 output}}}{36}{figure.caption.131}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {conv4 output}}}{36}{figure.caption.131}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {conv5 output}}}{36}{figure.caption.131}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Effects of SPP Layer}{36}{section.138}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Visiualisation of feature maps from the CNN model and the SPP model. The upper images are from the CNN model and the lower images are from the fine-tuned model.\relax }}{37}{figure.caption.139}}
\newlabel{fig:diff_featuremap}{{4.6}{37}{Visiualisation of feature maps from the CNN model and the SPP model. The upper images are from the CNN model and the lower images are from the fine-tuned model.\relax }{figure.caption.139}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Histogram distribution of vectors from FC7. The left is from CNN model and the right is from the SPP model.\relax }}{37}{figure.caption.140}}
\newlabel{fig:fc7_hist_output}{{4.7}{37}{Histogram distribution of vectors from FC7. The left is from CNN model and the right is from the SPP model.\relax }{figure.caption.140}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Error Results}{37}{section.141}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Conclusion and Future Work}{37}{section.149}}
\newlabel{fig:sunny}{{4.8(a)}{38}{Subfigure 4 4.8(a)}{subfigure.143}{}}
\newlabel{sub@fig:sunny}{{(a)}{38}{Subfigure 4 4.8(a)\relax }{subfigure.143}{}}
\newlabel{fig:sunny_conv1}{{4.8(b)}{38}{Subfigure 4 4.8(b)}{subfigure.144}{}}
\newlabel{sub@fig:sunny_conv1}{{(b)}{38}{Subfigure 4 4.8(b)\relax }{subfigure.144}{}}
\newlabel{fig:sunny_conv2}{{4.8(c)}{38}{Subfigure 4 4.8(c)}{subfigure.145}{}}
\newlabel{sub@fig:sunny_conv2}{{(c)}{38}{Subfigure 4 4.8(c)\relax }{subfigure.145}{}}
\newlabel{fig:sunny_conv3}{{4.8(d)}{38}{Subfigure 4 4.8(d)}{subfigure.146}{}}
\newlabel{sub@fig:sunny_conv3}{{(d)}{38}{Subfigure 4 4.8(d)\relax }{subfigure.146}{}}
\newlabel{fig:sunny_conv4}{{4.8(e)}{38}{Subfigure 4 4.8(e)}{subfigure.147}{}}
\newlabel{sub@fig:sunny_conv4}{{(e)}{38}{Subfigure 4 4.8(e)\relax }{subfigure.147}{}}
\newlabel{fig:sunny_conv5}{{4.8(f)}{38}{Subfigure 4 4.8(f)}{subfigure.148}{}}
\newlabel{sub@fig:sunny_conv5}{{(f)}{38}{Subfigure 4 4.8(f)\relax }{subfigure.148}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Misclassified images \citep  {lutwo}.\relax }}{38}{figure.caption.142}}
\newlabel{fig:Misclassification}{{4.8}{38}{Misclassified images \citep {lutwo}.\relax }{figure.caption.142}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {sunny}}}{38}{figure.caption.142}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {sunny}}}{38}{figure.caption.142}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {sunny}}}{38}{figure.caption.142}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {cloudy}}}{38}{figure.caption.142}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {cloudy}}}{38}{figure.caption.142}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {cloudy}}}{38}{figure.caption.142}}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Multilabel Learning}{39}{part.150}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Introduction}{40}{chapter.151}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter5}{{5}{40}{Introduction}{chapter.151}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Overview}{40}{section.152}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Example Image\relax }}{40}{figure.caption.153}}
\newlabel{fig:MultilableImage}{{5.1}{40}{Example Image\relax }{figure.caption.153}{}}
\citation{read2011classifier}
\citation{read2011classifier}
\citation{tsoumakas2006multi}
\citation{tsoumakas2007random}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Multilabel $Y_{1},...,Y_{L} \in 2^L$\relax }}{41}{table.caption.154}}
\newlabel{tab:MultilabelTable}{{5.1}{41}{Multilabel $Y_{1},...,Y_{L} \in 2^L$\relax }{table.caption.154}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Multi-Label Learning}{41}{section.155}}
\citation{ghamrawi2005collective}
\citation{tsoumakas2007random}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Background}{44}{chapter.156}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter6}{{6}{44}{Background}{chapter.156}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Evaluation Metrics}{44}{section.157}}
\newlabel{eq:UniLabel}{{6.1}{45}{Evaluation Metrics}{equation.158}{}}
\newlabel{eq:IndicatorFunc}{{6.2}{45}{Evaluation Metrics}{equation.159}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Example-based Metrics}{45}{subsection.160}}
\newlabel{eq:HammingLoss}{{6.3}{45}{Example-based Metrics}{equation.161}{}}
\newlabel{eq:SubsetAcu}{{6.4}{45}{Example-based Metrics}{equation.162}{}}
\newlabel{eq:Precision}{{6.5}{45}{Example-based Metrics}{equation.163}{}}
\newlabel{eq:Recall}{{6.6}{45}{Example-based Metrics}{equation.164}{}}
\newlabel{eq:Accuracy}{{6.7}{46}{Example-based Metrics}{equation.165}{}}
\newlabel{eq:F1Measure}{{6.8}{46}{Example-based Metrics}{equation.166}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Label-based Metrics}{46}{subsection.167}}
\newlabel{eq:MacroPrecision}{{6.9}{46}{Label-based Metrics}{equation.168}{}}
\newlabel{eq:MacroRecall}{{6.10}{46}{Label-based Metrics}{equation.169}{}}
\newlabel{eq:LabelAccuracy}{{6.11}{46}{Label-based Metrics}{equation.170}{}}
\newlabel{eq:MicroPrecision}{{6.12}{46}{Label-based Metrics}{equation.171}{}}
\newlabel{eq:MicroRecall}{{6.13}{46}{Label-based Metrics}{equation.172}{}}
\citation{gao2013consistency}
\newlabel{eq:LabelMicroAccuracy}{{6.14}{47}{Label-based Metrics}{equation.173}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Learning Algorithms}{47}{section.174}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Problem Transformation Methods}{47}{subsection.175}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1.1}Binary Relevance (BR)}{47}{subsubsection.176}}
\citation{read2011classifier}
\newlabel{eq:BinaryRelevance}{{6.15}{48}{Binary Relevance (BR)}{equation.177}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1.2}Classifier Chains (CC)}{48}{subsubsection.178}}
\newlabel{eq:ClassifierChains}{{6.16}{48}{Classifier Chains (CC)}{equation.179}{}}
\citation{zhang2007ml}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Algorithm Adaptation Methods}{49}{subsection.180}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2.1}Multi-label k-Nearest Neighbour (ML-kNN)}{49}{subsubsection.181}}
\newlabel{eq:KNNCounting}{{6.17}{49}{Multi-label k-Nearest Neighbour (ML-kNN)}{equation.182}{}}
\citation{ghamrawi2005collective}
\newlabel{eq:CategoryVec}{{6.18}{50}{Multi-label k-Nearest Neighbour (ML-kNN)}{equation.183}{}}
\newlabel{eq:CategoryVecBay}{{6.19}{50}{Multi-label k-Nearest Neighbour (ML-kNN)}{equation.184}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2.2}Collective Multi-label Classifier (CML)}{50}{subsubsection.185}}
\newlabel{eq:CMLExpect}{{6.20}{50}{Collective Multi-label Classifier (CML)}{equation.186}{}}
\newlabel{eq:CMLOptimal}{{6.21}{51}{Collective Multi-label Classifier (CML)}{equation.187}{}}
\newlabel{eq:CMLLabel}{{6.22}{51}{Collective Multi-label Classifier (CML)}{equation.188}{}}
\citation{ColourWheel}
\citation{ColourWheel}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Methodology}{52}{chapter.189}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter7}{{7}{52}{Methodology}{chapter.189}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Artificial Dataset}{52}{section.190}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Colour Wheel Diagram \citep  {ColourWheel}\relax }}{52}{figure.caption.191}}
\newlabel{fig:ColorWheel}{{7.1}{52}{Colour Wheel Diagram \citep {ColourWheel}\relax }{figure.caption.191}{}}
\citation{barron1993universal}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Generating Images}{53}{subsection.192}}
\newlabel{eq:FormulationHue}{{7.1}{53}{Generating Images}{equation.193}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Artificial Neural Networks (ANNs)}{53}{section.211}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Multilabel samples and the RGB colour histograms. Three labels mean red, green and blue sequentially. \relax }}{54}{figure.caption.194}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Label:1 -1 1}}}{54}{figure.caption.194}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Label:1 1 -1}}}{54}{figure.caption.194}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {Label:-1 1 -1}}}{54}{figure.caption.194}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(m)}{\ignorespaces {Label:-1 -1 1}}}{54}{figure.caption.194}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Network Architecture}{54}{subsection.212}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Network Topology For Multi-lable Classification\relax }}{55}{figure.caption.213}}
\newlabel{fig:MultiLabelNet}{{7.3}{55}{Network Topology For Multi-lable Classification\relax }{figure.caption.213}{}}
\newlabel{eq:MultiLableError}{{7.2}{55}{Network Architecture}{equation.214}{}}
\newlabel{eq:MultiLableSamError}{{7.3}{55}{Network Architecture}{equation.215}{}}
\newlabel{eq:MultiLableGlobalError}{{7.4}{56}{Network Architecture}{equation.216}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}Error Function}{56}{subsection.217}}
\citation{bermejo2001oriented}
\newlabel{eq:JointProbDensity}{{7.5}{57}{Error Function}{equation.218}{}}
\newlabel{eq:ProbDensityX}{{7.6}{57}{Error Function}{equation.219}{}}
\newlabel{eq:LikelihoodLoss}{{7.7}{57}{Error Function}{equation.220}{}}
\newlabel{eq:LikelihoodErrorFunc}{{7.8}{57}{Error Function}{equation.221}{}}
\newlabel{eq:SimLikelihoodErrorFunc}{{7.9}{57}{Error Function}{equation.222}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}Cross Entropy}{58}{subsection.223}}
\newlabel{eq:RelativeEngtropy}{{7.10}{58}{Cross Entropy}{equation.224}{}}
\newlabel{eq:EquationNN}{{7.11}{58}{Cross Entropy}{equation.225}{}}
\newlabel{eq:TwoClassCrossEntropyCostFunc}{{7.12}{58}{Cross Entropy}{equation.226}{}}
\newlabel{eq:DerCrossEntropyCostFunc}{{7.13}{59}{Cross Entropy}{equation.227}{}}
\newlabel{eq:SecondDerCrossEntropyCostFunc}{{7.15}{59}{Cross Entropy}{equation.228}{}}
\newlabel{eq:SimDerCrossEntropyCostFunc}{{7.16}{59}{Cross Entropy}{equation.229}{}}
\newlabel{eq:BiasCrossEntropyCostFunc}{{7.17}{59}{Cross Entropy}{equation.230}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.4}Training and Testing}{60}{subsection.231}}
\newlabel{eq:MultiLabelActivation}{{7.18}{60}{Training and Testing}{equation.232}{}}
\newlabel{eq:MultiLabel}{{7.19}{60}{Training and Testing}{equation.233}{}}
\newlabel{eq:MultiLableErrorDif}{{7.20}{60}{Training and Testing}{equation.234}{}}
\newlabel{eq:MultiLableChainRule}{{7.21}{60}{Training and Testing}{equation.235}{}}
\newlabel{eq:MultiLablePartialC}{{7.22}{60}{Training and Testing}{equation.236}{}}
\newlabel{eq:MultiLableGenErr}{{7.23}{60}{Training and Testing}{equation.237}{}}
\citation{elisseeff2001kernel}
\newlabel{eq:MultiLableGenErrS}{{7.24}{61}{Training and Testing}{equation.238}{}}
\newlabel{eq:MultiLablePartialE}{{7.25}{61}{Training and Testing}{equation.239}{}}
\newlabel{eq:MultiLableGenErrEs}{{7.26}{61}{Training and Testing}{equation.240}{}}
\newlabel{eq:MultiLableGenErrEsFin}{{7.27}{61}{Training and Testing}{equation.241}{}}
\newlabel{eq:MultiLableUpdateWeights}{{7.28}{61}{Training and Testing}{equation.242}{}}
\newlabel{eq:MultiLableUpdateHidWeights}{{7.29}{61}{Training and Testing}{equation.243}{}}
\newlabel{eq:MultiLableUpdateBias}{{7.30}{61}{Training and Testing}{equation.244}{}}
\newlabel{eq:MultiLableThreshFunc}{{7.31}{62}{Training and Testing}{equation.245}{}}
\citation{lippmann1987introduction}
\citation{kolmogorov1963representation}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Experiment}{63}{chapter.246}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter8}{{8}{63}{Experiment}{chapter.246}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Dataset}{63}{section.247}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Details of Network}{63}{section.248}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Network Topology\relax }}{64}{figure.caption.249}}
\newlabel{fig:MLtopology}{{8.1}{64}{Network Topology\relax }{figure.caption.249}{}}
\citation{heaton2008introduction}
\@writefile{lot}{\contentsline {table}{\numberline {8.1}{\ignorespaces Test results for different number of hidden neurons.\relax }}{66}{table.caption.260}}
\newlabel{tb:tMLtestneurons}{{8.1}{66}{Test results for different number of hidden neurons.\relax }{table.caption.260}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Results}{66}{section.259}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces The test results for different number of hidden neurons. Blue circle for Sensitivity. Black plus for Specificity. Cyan star for Harmonic Mean. Red dot for Precission. Green x for F1 Score.\relax }}{66}{figure.caption.261}}
\newlabel{fig:MLtestneurons}{{8.2}{66}{The test results for different number of hidden neurons. Blue circle for Sensitivity. Black plus for Specificity. Cyan star for Harmonic Mean. Red dot for Precission. Green x for F1 Score.\relax }{figure.caption.261}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces The learning speed for 200 neurons in the hidden layer. Blue circle for Sensitivity. Black plus for Specificity. Cyan star for Harmonic Mean. Red dot for Precission. Green x for F1 Score.\relax }}{67}{figure.caption.262}}
\newlabel{fig:MLLearningRates}{{8.3}{67}{The learning speed for 200 neurons in the hidden layer. Blue circle for Sensitivity. Black plus for Specificity. Cyan star for Harmonic Mean. Red dot for Precission. Green x for F1 Score.\relax }{figure.caption.262}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces The ROC curve for 200 hidden neurons\relax }}{67}{figure.caption.263}}
\newlabel{fig:MLROCCurve}{{8.4}{67}{The ROC curve for 200 hidden neurons\relax }{figure.caption.263}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.5}{\ignorespaces The ROC curve for 200 hidden neurons\relax }}{68}{figure.caption.264}}
\newlabel{fig:MLROCCurveExt}{{8.5}{68}{The ROC curve for 200 hidden neurons\relax }{figure.caption.264}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Conclusion and Future Work}{68}{section.265}}
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\vspace  {2em}}
\bibstyle{unsrtnat}
\bibdata{Bibliography}
\bibcite{NeuronFigure1}{{1}{2014}{{Neu}}{{}}}
\bibcite{ErrorFigure1}{{2}{2014}{{Err}}{{}}}
\bibcite{GenerateNN}{{3}{2014}{{Gen}}{{}}}
\bibcite{zainal2013oil}{{4}{2013}{{Zainal-Mokhtar and Mohamad-Saleh}}{{}}}
\bibcite{OverfittingFigure}{{5}{2013}{{Ove}}{{}}}
\bibcite{srivastava2014dropout}{{6}{2014}{{Srivastava et~al.}}{{Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov}}}
\bibcite{CNNDiagram}{{7}{2015}{{CNN}}{{}}}
\bibcite{lazebnik2006beyond}{{8}{2006}{{Lazebnik et~al.}}{{Lazebnik, Schmid, and Ponce}}}
\bibcite{TransferlearningDiagram}{{9}{2012}{{Tra}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{69}{dummy.266}}
\newlabel{Bibliography}{{6}{69}{Conclusion and Future Work}{dummy.266}{}}
\bibcite{deng2009imagenet}{{10}{2009}{{Deng et~al.}}{{Deng, Dong, Socher, Li, Li, and Fei-Fei}}}
\bibcite{lutwo}{{11}{2014}{{Lu et~al.}}{{Lu, Lin, Jia, and Tang}}}
\bibcite{he2014spatial}{{12}{2014}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{krizhevsky2012imagenet}{{13}{2012}{{Krizhevsky et~al.}}{{Krizhevsky, Sutskever, and Hinton}}}
\bibcite{ColourWheel}{{14}{2016}{{Col}}{{}}}
\bibcite{bishop1995neural}{{15}{1995}{{Bishop}}{{}}}
\bibcite{roser2008classification}{{16}{2008}{{Roser and Moosmann}}{{}}}
\bibcite{serrano2002computationally}{{17}{2002}{{Serrano et~al.}}{{Serrano, Savakis, and Luo}}}
\bibcite{gokalp2007scene}{{18}{2007}{{Gokalp and Aksoy}}{{}}}
\bibcite{szummer1998indoor}{{19}{1998}{{Szummer and Picard}}{{}}}
\bibcite{shotton2009textonboost}{{20}{2009}{{Shotton et~al.}}{{Shotton, Winn, Rother, and Criminisi}}}
\bibcite{vailaya2002automatic}{{21}{2002}{{Vailaya et~al.}}{{Vailaya, Zhang, Yang, Liu, and Jain}}}
\bibcite{boutell2004learning}{{22}{2004}{{Boutell et~al.}}{{Boutell, Luo, Shen, and Brown}}}
\bibcite{yan2009weather}{{23}{2009}{{Yan et~al.}}{{Yan, Luo, and Zheng}}}
\bibcite{mcculloch1943logical}{{24}{1943}{{McCulloch and Pitts}}{{}}}
\bibcite{robbins1985convergence}{{25}{1985}{{Robbins and Siegmund}}{{}}}
\bibcite{hinton1987learning}{{26}{1987}{{Hinton}}{{}}}
\bibcite{lecun1998gradient}{{27}{1998}{{LeCun et~al.}}{{LeCun, Bottou, Bengio, and Haffner}}}
\bibcite{pan2010survey}{{28}{2010}{{Pan and Yang}}{{}}}
\bibcite{russell2008labelme}{{29}{2008}{{Russell et~al.}}{{Russell, Torralba, Murphy, and Freeman}}}
\bibcite{xiao2010sun}{{30}{2010}{{Xiao et~al.}}{{Xiao, Hays, Ehinger, Oliva, Torralba, et~al.}}}
\bibcite{nair2010rectified}{{31}{2010}{{Nair and Hinton}}{{}}}
\bibcite{jia2014caffe}{{32}{2014}{{Jia et~al.}}{{Jia, Shelhamer, Donahue, Karayev, Long, Girshick, Guadarrama, and Darrell}}}
\bibcite{ZeilerF13}{{33}{2013}{{Zeiler and Fergus}}{{}}}
\bibcite{razavian2014cnn}{{34}{2014}{{Razavian et~al.}}{{Razavian, Azizpour, Sullivan, and Carlsson}}}
\bibcite{read2011classifier}{{35}{2011}{{Read et~al.}}{{Read, Pfahringer, Holmes, and Frank}}}
\bibcite{tsoumakas2006multi}{{36}{2006}{{Tsoumakas and Katakis}}{{}}}
\bibcite{tsoumakas2007random}{{37}{2007}{{Tsoumakas and Vlahavas}}{{}}}
\bibcite{ghamrawi2005collective}{{38}{2005}{{Ghamrawi and McCallum}}{{}}}
\bibcite{gao2013consistency}{{39}{2013}{{Gao and Zhou}}{{}}}
\bibcite{zhang2007ml}{{40}{2007}{{Zhang and Zhou}}{{}}}
\bibcite{barron1993universal}{{41}{1993}{{Barron}}{{}}}
\bibcite{bermejo2001oriented}{{42}{2001}{{Bermejo and Cabestany}}{{}}}
\bibcite{elisseeff2001kernel}{{43}{2001}{{Elisseeff and Weston}}{{}}}
\bibcite{lippmann1987introduction}{{44}{1987}{{Lippmann}}{{}}}
\bibcite{kolmogorov1963representation}{{45}{1963}{{Kolmogorov}}{{}}}
\bibcite{heaton2008introduction}{{46}{2008}{{Heaton}}{{}}}
