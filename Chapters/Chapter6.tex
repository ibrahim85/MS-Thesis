% Chapter 6

\chapter{Background} % Write in your own chapter title
\label{Chapter6}
\lhead{Chapter 6. \emph{Background}}

Compare to general classification, multi-label classification has different evaluation metrics and learning algorithms.

\section{Evaluation Metrics}

In supervised learning settings, different metrics, like accuracy and area under the ROC curve, are used to evaluate the generalization performance of learning system. In multi-label learning, evaluating performance is more complicated  than single-label problems with the increasing number of labels simultaneously. Therefore, two main types of evaluation methods are implemented in multi-label learning, say example-based metrics\citep{ghamrawi2005collective} and label-metrics\citep{tsoumakas2007random}.

The two types of metrics evaluate the outputs of classifier from different perspective. Given that $S = {(x_{i}, Y_{i})}$ is the test instance and $h(\cdot)$ is the learned multi-label classifier. Example-based metrics achieve all class labels of each test example, and then compute the mean value of test set to evaluate generalization performance. Compared to considering all class labels simultaneously, label-based metrics evaluate performance by treating each class label separately and computing macro/micro-averaged value of all class labels.

In a supervised classification problem, there have a ground truth output and a predicted output of test instance. So the results of each test instance can be be assigned to one of the four categories:
\begin{itemize}
\item True Positive (TP) - label is positive and prediction is also positive
\item True Negative (TN) - label is negative and prediction is also negative
\item False Positive (FP) - label is negative but prediction is positive
\item False Negative (FN) - label is positive but prediction is negative
\end{itemize}

Here we define a set $D$ of $N$ instances and $Y_{i}$ to be a family of ground truth label sets and $P_{i} = h(x_{i})$ to be a family of predicted label set. The set of all unique labels is
\begin{equation}\label{eq:UniLabel}
L = \bigcup_{i=0}^{N-1} L_{i}
\end{equation}
While the definition of indicator function $I_{A}$ on a set $A$ is presented as
\begin{equation}\label{eq:IndicatorFunc}
I_{A}(x) =
  \begin{cases}
    1       & \quad \text{if } x \in A\\
    0  & \quad \text{otherwise}\\
  \end{cases}
\end{equation}

\subsection{Example-based Metrics}

\textbf{Hamming Loss} evaluates performance via counting the number of misclassification labels. The smaller value of hamming loss, the better performance.
\begin{equation}\label{eq:HammingLoss}
\frac{1}{N \cdot \left|L\right|} \sum_{i=0}^{N - 1} \left|L_i\right| + \left|P_i\right| - 2\left|L_i
          \cap P_i\right|
\end{equation}

\textbf{Subset Accuracy} evaluates the fraction of correctly predicted instance while the predicted label set is identical to the ground truth label set. It is equivalent to traditional accuracy metric.
\begin{equation}\label{eq:SubsetAcu}
\frac{1}{N} \sum_{i=0}^{N-1} I_{\{L_i\}}(P_i)
\end{equation}

\textbf{Precision} is defined as
\begin{equation}\label{eq:Precision}
\frac{1}{N} \sum_{i=0}^{N-1} \frac{\left|L_i \cap P_i\right|}{\left|P_i\right|}
\end{equation}

\textbf{Recall} is defined as
\begin{equation}\label{eq:Recall}
\frac{1}{N} \sum_{i=0}^{N-1} \frac{\left|L_i \cap P_i\right|}{\left|L_i\right|}
\end{equation}

\textbf{Accuracy} is defined as
\begin{equation}\label{eq:Accuracy}
\frac{1}{N} \sum_{i=0}^{N - 1} \frac{\left|L_i \cap P_i \right|}
        {\left|L_i\right| + \left|P_i\right| - \left|L_i \cap P_i \right|}
\end{equation}

\textbf{F1 Measure} is an integrated version combined by harmonic mean of \textbf{Precision} and \textbf{Recall}. 
\begin{equation}\label{eq:Accuracy}
\frac{1}{N} \sum_{i=0}^{N-1} 2 \frac{\left|P_i \cap L_i\right|}{\left|P_i\right| \cdot \left|L_i\right|}
\end{equation}

\subsection{Label-based Metrics}

\textbf{Macro Precision} (precision averaged across all labels) is defined as
\begin{equation}\label{eq:MacroPrecision}
PPV(\ell)=\frac{TP}{TP + FP}=
          \frac{\sum_{i=0}^{N-1} I_{P_i}(\ell) \cdot I_{L_i}(\ell)}
          {\sum_{i=0}^{N-1} I_{P_i}(\ell)}
\end{equation}

\textbf{Macro Recall} (recall averaged across all labels) is defined as
\begin{equation}\label{eq:MacroRecall}
TPR(\ell)=\frac{TP}{P}=
          \frac{\sum_{i=0}^{N-1} I_{P_i}(\ell) \cdot I_{L_i}(\ell)}
          {\sum_{i=0}^{N-1} I_{L_i}(\ell)}
\end{equation}

\textbf{F1 Measure by label} is the harmonic mean between \textbf{Precision} and \textbf{Recall}. 
\begin{equation}\label{eq:LabelAccuracy}
F1(\ell) = 2
                            \cdot \left(\frac{PPV(\ell) \cdot TPR(\ell)}
                            {PPV(\ell) + TPR(\ell)}\right)
\end{equation}

\textbf{Micro Precision} (precision averaged over all the example/label pairs) is defined as
\begin{equation}\label{eq:MicroPrecision}
\frac{TP}{TP + FP}=\frac{\sum_{i=0}^{N-1} \left|P_i \cap L_i\right|}
          {\sum_{i=0}^{N-1} \left|P_i \cap L_i\right| + \sum_{i=0}^{N-1} \left|P_i - L_i\right|}
\end{equation}

\textbf{Micro Recall} (recall averaged over all the example/label pairs) is defined as
\begin{equation}\label{eq:MicroRecall}
\frac{TP}{TP + FN}=\frac{\sum_{i=0}^{N-1} \left|P_i \cap L_i\right|}
        {\sum_{i=0}^{N-1} \left|P_i \cap L_i\right| + \sum_{i=0}^{N-1} \left|L_i - P_i\right|}
\end{equation}

\textbf{Micro F1 Measure by label} is the harmonic mean between \textbf{Micro Precision} and \textbf{Micro Recall}. 
\begin{equation}\label{eq:LabelMicroAccuracy}
2 \cdot \frac{TP}{2 \cdot TP + FP + FN}=2 \cdot \frac{\sum_{i=0}^{N-1} \left|P_i \cap L_i\right|}{2 \cdot
        \sum_{i=0}^{N-1} \left|P_i \cap L_i\right| + \sum_{i=0}^{N-1} \left|L_i - P_i\right| + \sum_{i=0}^{N-1}
        \left|P_i - L_i\right|}
\end{equation}

For the label-based metrics, the larger the metrics value means the higher generalization performance.

With the previous metrics, there are diverse methods to evaluate model generalization performance. In most multi-label training, learning algorithms optimize one of the metrics. To make evaluation fair and precise, the learning algorithms should be tested on different metrics to evaluate performance to avoid bias.

Most multi-label metrics are non-convex and discrete, most algorithms turn to optimize alternative multi-label metrics. Recently, some researcher study the consistency of multi-label learning\citep{gao2013consistency}. For example, it is ad hot to figure out if the loss of classifier converges to the Bayes loss while increasing training set size.


\section{Learning Algorithms}

Algorithms play key role in the literature of machine learning, so there is no exception in multi-label learning. The capability of representation is an important criterion to evaluate the performance of a algorithm. Otherwise, there are some related criteria to be consider. Firstly, broad spectrum is considered. If the algorithm can cover an range of algorithmic design strategies with unique characteristics. Secondly, it is reasonable to evaluate the impact which the algorithm poses on the multi-label learning settings. Last, the algorithm complexity is a critical factor if the algorithm can be used in practice.

\subsection{Problem Transformation Methods}

\subsubsection{Binary Relevance}

Binary Relevance is a elementary algorithm which decomposes multi-label learning problem into a set of independent binary classification problems in which each problem harmonizes a label of the $q$ labels in the set $L = {y_{1}, y_{2},...,y_{q}}$. The approach initially transforms multi-label dataset into $q$ binary datasets $D_{y_{i}} (i = 1,2,...,q)$, where each $D_{Y_{I}}$ includes all samples of the multi-label dataset and has a single binary label to instruct if the dataset has or has no attribute to relevant label. For example, if a sample has a positive value means that the sample owns the correlation label, otherwise, it does not own it. After transforming dataset, a set of $q$ binary classifiers, say $H_{i}(E) (i = 1,2,...,q)$, has been built up using the respective training dataset $D_{y_{i}}$. 

\begin{equation}\label{eq:BinaryRelevance}
H = \{C_{y_{i}}(x, y_{i}) \to y'_{i} \in \{0,1\}| y \in L, i = 1,2,...,q\}
\end{equation}

To classify a new multi-label sample, Binary Relevance outputs the collection of labels which are predicted with positive value by the independent binary classifiers.

Binary Relevance combines computational efficiency and simple implementation. With a constant number of samples, the algorithm scales with size $q$ of label set $L$. Supposing that each classifier has complexity $f(|X|,|D|)$, Binary Relevance has complexity $O(qxf(|X|,|D|))$. With limit number of $q$, Binary Relevance can be regarded as a simple and effective method.

One of the disadvantages of Binary Relevance is the limitation of label relationship information. Given that all labels are independent, Binary Relevance discards the information among labels.

\subsubsection{Classifier Chains}

To improve the performance of Binary Relevance, classifier chains has been introduced in multi-label classification literature\citep{read2011classifier}. The algorithm transform multi-label learning problems into a chain of binary classifiers based on label dependence.

For a set of $q$ labels $L$, Classifier Chains model learns $q$ classifiers as Binary Relevance does. However, it links all classifiers through feature space. Given that there are a set of samples $D(x,y_{i}) (i = 1,2,...,q)$ where $y_{i}$ is a subset of labels $L$ and $x$ is domain of dataset. We transform the dataset into $q$ datasets in which the $j$-th sample is based on datasets and previous labels

\begin{equation}\label{eq:ClassifierChains}
H = \{C_{y_{i}}(x, y_{1},y_{2},...,y_{i-1}) \to y'_{i} \in \{0,1\}| y \in L, i = 1,2,...,q\}
\end{equation}

Thus it forms a train of binary classifier $C_{1},C_{2},...,C_{q}$. Each classifier $C_{i}$ learns and predicts the binary association of label $y_{i}$ based on the dataset $x$ and all prior binary relevance predictions $y_{j}, j = 1,2,...,i-1$. The learning process starts from $C_{1}$ and follows the china step by step. Therefore, $C_{1}$ determines $p(y_{1}|x)$ and each classifier, say $C_{2},...,C_{q}$, determines $p(y_{i}|x_{i},y_{1},...,y_{i-1})$.

The Classifier Chains method propagates label information through classifiers, and post classifier takes into account previous predictions. This can overcome issues of ignorant label correlation in some degree. At the same time, the method keep benefits of Binary Relevance including computation efficiency and memory efficiency. The computational complexity of Classifier Chains can be close to Binary Relevance depending on the size of labels and complexity of elemental classifiers $C_{i}$. As stated in previous, the complexity of Binary Relevance is $O(qxf(|X|,|D|))$ where $f(|X|,|D|))$ is the complexity of elemental classifier. With extra computation introduced by previous labels, the complexity of Classifier Chains is $O(qxf(|X|+q,|D|))$, while the complexity will be worse in case $q \gg |X|$.

\subsection{Algorithm Adaptation Methods}

\subsubsection{Multi-label k-Nearest Neighbor(ML-kNN)}

The algorithm adapts k-nearest neighbor techniques to propose multi-label data and utilize maximum a posteriori (MAP) to make prediction through reasoning embodied labelling information among neighbour \citep{zhang2007ml}.

Given dataset $X$ and its label set $Y$, $y$ represents output vector for $x$ where $i$-th element $y(i)$ is positive if $i \in Y$, otherwise it is negative. Suppose that $N(x)$ is the set of neighbour of $x$ in training set, we can compute a membership counting vector which represents the number of neighbours of $x$ owning $l$-th label.

\begin{equation}\label{eq:KNNCounting}
C_{x}(i) = \sum_{a \in N(x)} y_{a}(i), i \in Y
\end{equation}

To test a new sample $t$, the algorithm sorts out its category in training dataset by kNN $N(t)$. Let $H_{1}^l$ denote that $t$ has label $l$ and $H_{0}^l$ denote that $t$ do not have label $l$. There are $j$ samples have label $l$, say $E_{j}^l (j \in {0,1,...,k})$. Then the category vector $y_{t}$ is determined via the MAP principle:

\begin{equation}\label{eq:CategoryVec}
y_{t}(l) = \operatorname*{arg\,max}_{b \in \{0,1\}} P(H_{b}^l|E_{C_{t}(i) }^l) l \in Y
\end{equation}

With the Bayesian rule, \ref{eq:CategoryVec} can be represented as

\begin{equation}\label{eq:CategoryVecBay}
y_{t}(l) = \operatorname*{arg\,max}_{b \in \{0,1\}} P(H_{b}^l)P(E_{C_{t}(i) }^l|H_{b}^l) l \in Y
\end{equation}

As stated in \ref{eq:CategoryVecBay}, the output of test sample $t$ is $y_{t}(l)$. It can be computed via prior probability $P(H_{b}^l) l \in Y, b \in \{0,1\}$ and the posterior probability $P(E_{j}^l|H_{b}^l) (j \in \{0,1,...,k\})$.

\subsubsection{Collective Multi-label Classifier(CML)}

Supposed that labels are highly interdependent in some scenarios, CML explores multi-label conditional random field (CRF) classification models which learn  parameters for each pair of labels directly\citep{ghamrawi2005collective}.

In dataset $(x,Y)$, each sample has a corresponding random variables representation $(x,y)$ in which $y = (y_{1},y_{2},...,y_{q}) y_{i} \in \{-1,1\}$ is binary label vector. If the sample contains $j$-th label, the $j$-th element of $y$ is $1$, otherwise $-1$. Then the aim of multi-label learning is to learn the joint probability distribution $p(x,y)$.

The entropy of $(x,y)$ is represented as $H_{p}(x,y)$ and gives the distribution $p(\cdot,\cdot)$ of $(x,y)$. The principle of maximum entropy can be achieved by maximizing $H_{p}(x,y)$. The fact is expressed with constrains on expectation of function $f(x,y)$. The expected value can be estimated from training dataset

\begin{equation}\label{eq:CMLExpect}
F_{k} = \frac{1}{m}\sum_{(x,y) \in D}f_{k}(x,y)
\end{equation}

According to normalization constraint on $p(\cdot,\cdot)$, the optimal solution can be represented as:

\begin{equation}\label{eq:CMLOptimal}
p(y|x) = \frac{1}{Z(x)}exp(\sum_{k \in K}\lambda_{k} \cdot f_{k}(x,y))
\end{equation}

Yielding to Gaussian distribution, parameters can be found in a convex log-posterior probability function. For a test sample $x$, the predicted label set follows to:

\begin{equation}\label{eq:CMLLabel}
y_{x} = \operatorname*{arg\,max}_{y} p(y|x)
\end{equation}

It is notable that the exact inference is only suitable for small label space via arg max, because it needs to reduce the search space of arg max significantly via pruning strategies. CML is a second-order approach which considers correlations between every label pair constrains in $k_{2}$. 